{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: chromadb in /Users/alice3e/.pyenv/versions/3.13.5/lib/python3.13/site-packages (1.3.7)\n",
      "Requirement already satisfied: build>=1.0.3 in /Users/alice3e/.pyenv/versions/3.13.5/lib/python3.13/site-packages (from chromadb) (1.3.0)\n",
      "Requirement already satisfied: pydantic>=1.9 in /Users/alice3e/.pyenv/versions/3.13.5/lib/python3.13/site-packages (from chromadb) (2.12.5)\n",
      "Requirement already satisfied: pybase64>=1.4.1 in /Users/alice3e/.pyenv/versions/3.13.5/lib/python3.13/site-packages (from chromadb) (1.4.3)\n",
      "Requirement already satisfied: uvicorn>=0.18.3 in /Users/alice3e/.pyenv/versions/3.13.5/lib/python3.13/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.40.0)\n",
      "Requirement already satisfied: numpy>=1.22.5 in /Users/alice3e/.pyenv/versions/3.13.5/lib/python3.13/site-packages (from chromadb) (2.4.0)\n",
      "Requirement already satisfied: posthog<6.0.0,>=2.4.0 in /Users/alice3e/.pyenv/versions/3.13.5/lib/python3.13/site-packages (from chromadb) (5.4.0)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /Users/alice3e/.pyenv/versions/3.13.5/lib/python3.13/site-packages (from chromadb) (4.15.0)\n",
      "Requirement already satisfied: onnxruntime>=1.14.1 in /Users/alice3e/.pyenv/versions/3.13.5/lib/python3.13/site-packages (from chromadb) (1.23.2)\n",
      "Requirement already satisfied: opentelemetry-api>=1.2.0 in /Users/alice3e/.pyenv/versions/3.13.5/lib/python3.13/site-packages (from chromadb) (1.39.1)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in /Users/alice3e/.pyenv/versions/3.13.5/lib/python3.13/site-packages (from chromadb) (1.39.1)\n",
      "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /Users/alice3e/.pyenv/versions/3.13.5/lib/python3.13/site-packages (from chromadb) (1.39.1)\n",
      "Requirement already satisfied: tokenizers>=0.13.2 in /Users/alice3e/.pyenv/versions/3.13.5/lib/python3.13/site-packages (from chromadb) (0.22.1)\n",
      "Requirement already satisfied: pypika>=0.48.9 in /Users/alice3e/.pyenv/versions/3.13.5/lib/python3.13/site-packages (from chromadb) (0.48.9)\n",
      "Requirement already satisfied: tqdm>=4.65.0 in /Users/alice3e/.pyenv/versions/3.13.5/lib/python3.13/site-packages (from chromadb) (4.67.1)\n",
      "Requirement already satisfied: overrides>=7.3.1 in /Users/alice3e/.pyenv/versions/3.13.5/lib/python3.13/site-packages (from chromadb) (7.7.0)\n",
      "Requirement already satisfied: importlib-resources in /Users/alice3e/.pyenv/versions/3.13.5/lib/python3.13/site-packages (from chromadb) (6.5.2)\n",
      "Requirement already satisfied: grpcio>=1.58.0 in /Users/alice3e/.pyenv/versions/3.13.5/lib/python3.13/site-packages (from chromadb) (1.76.0)\n",
      "Requirement already satisfied: bcrypt>=4.0.1 in /Users/alice3e/.pyenv/versions/3.13.5/lib/python3.13/site-packages (from chromadb) (5.0.0)\n",
      "Requirement already satisfied: typer>=0.9.0 in /Users/alice3e/.pyenv/versions/3.13.5/lib/python3.13/site-packages (from chromadb) (0.20.1)\n",
      "Requirement already satisfied: kubernetes>=28.1.0 in /Users/alice3e/.pyenv/versions/3.13.5/lib/python3.13/site-packages (from chromadb) (34.1.0)\n",
      "Requirement already satisfied: tenacity>=8.2.3 in /Users/alice3e/.pyenv/versions/3.13.5/lib/python3.13/site-packages (from chromadb) (9.1.2)\n",
      "Requirement already satisfied: pyyaml>=6.0.0 in /Users/alice3e/.pyenv/versions/3.13.5/lib/python3.13/site-packages (from chromadb) (6.0.3)\n",
      "Requirement already satisfied: mmh3>=4.0.1 in /Users/alice3e/.pyenv/versions/3.13.5/lib/python3.13/site-packages (from chromadb) (5.2.0)\n",
      "Requirement already satisfied: orjson>=3.9.12 in /Users/alice3e/.pyenv/versions/3.13.5/lib/python3.13/site-packages (from chromadb) (3.11.5)\n",
      "Requirement already satisfied: httpx>=0.27.0 in /Users/alice3e/.pyenv/versions/3.13.5/lib/python3.13/site-packages (from chromadb) (0.28.1)\n",
      "Requirement already satisfied: rich>=10.11.0 in /Users/alice3e/.pyenv/versions/3.13.5/lib/python3.13/site-packages (from chromadb) (14.2.0)\n",
      "Requirement already satisfied: jsonschema>=4.19.0 in /Users/alice3e/.pyenv/versions/3.13.5/lib/python3.13/site-packages (from chromadb) (4.25.1)\n",
      "Requirement already satisfied: requests<3.0,>=2.7 in /Users/alice3e/.pyenv/versions/3.13.5/lib/python3.13/site-packages (from posthog<6.0.0,>=2.4.0->chromadb) (2.32.5)\n",
      "Requirement already satisfied: six>=1.5 in /Users/alice3e/.pyenv/versions/3.13.5/lib/python3.13/site-packages (from posthog<6.0.0,>=2.4.0->chromadb) (1.17.0)\n",
      "Requirement already satisfied: python-dateutil>=2.2 in /Users/alice3e/.pyenv/versions/3.13.5/lib/python3.13/site-packages (from posthog<6.0.0,>=2.4.0->chromadb) (2.9.0.post0)\n",
      "Requirement already satisfied: backoff>=1.10.0 in /Users/alice3e/.pyenv/versions/3.13.5/lib/python3.13/site-packages (from posthog<6.0.0,>=2.4.0->chromadb) (2.2.1)\n",
      "Requirement already satisfied: distro>=1.5.0 in /Users/alice3e/.pyenv/versions/3.13.5/lib/python3.13/site-packages (from posthog<6.0.0,>=2.4.0->chromadb) (1.9.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/alice3e/.pyenv/versions/3.13.5/lib/python3.13/site-packages (from requests<3.0,>=2.7->posthog<6.0.0,>=2.4.0->chromadb) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/alice3e/.pyenv/versions/3.13.5/lib/python3.13/site-packages (from requests<3.0,>=2.7->posthog<6.0.0,>=2.4.0->chromadb) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/alice3e/.pyenv/versions/3.13.5/lib/python3.13/site-packages (from requests<3.0,>=2.7->posthog<6.0.0,>=2.4.0->chromadb) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/alice3e/.pyenv/versions/3.13.5/lib/python3.13/site-packages (from requests<3.0,>=2.7->posthog<6.0.0,>=2.4.0->chromadb) (2025.11.12)\n",
      "Requirement already satisfied: packaging>=19.1 in /Users/alice3e/.pyenv/versions/3.13.5/lib/python3.13/site-packages (from build>=1.0.3->chromadb) (25.0)\n",
      "Requirement already satisfied: pyproject_hooks in /Users/alice3e/.pyenv/versions/3.13.5/lib/python3.13/site-packages (from build>=1.0.3->chromadb) (1.2.0)\n",
      "Requirement already satisfied: anyio in /Users/alice3e/.pyenv/versions/3.13.5/lib/python3.13/site-packages (from httpx>=0.27.0->chromadb) (4.12.0)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/alice3e/.pyenv/versions/3.13.5/lib/python3.13/site-packages (from httpx>=0.27.0->chromadb) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /Users/alice3e/.pyenv/versions/3.13.5/lib/python3.13/site-packages (from httpcore==1.*->httpx>=0.27.0->chromadb) (0.16.0)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /Users/alice3e/.pyenv/versions/3.13.5/lib/python3.13/site-packages (from jsonschema>=4.19.0->chromadb) (25.4.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /Users/alice3e/.pyenv/versions/3.13.5/lib/python3.13/site-packages (from jsonschema>=4.19.0->chromadb) (2025.9.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /Users/alice3e/.pyenv/versions/3.13.5/lib/python3.13/site-packages (from jsonschema>=4.19.0->chromadb) (0.37.0)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /Users/alice3e/.pyenv/versions/3.13.5/lib/python3.13/site-packages (from jsonschema>=4.19.0->chromadb) (0.30.0)\n",
      "Requirement already satisfied: google-auth>=1.0.1 in /Users/alice3e/.pyenv/versions/3.13.5/lib/python3.13/site-packages (from kubernetes>=28.1.0->chromadb) (2.45.0)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /Users/alice3e/.pyenv/versions/3.13.5/lib/python3.13/site-packages (from kubernetes>=28.1.0->chromadb) (1.9.0)\n",
      "Requirement already satisfied: requests-oauthlib in /Users/alice3e/.pyenv/versions/3.13.5/lib/python3.13/site-packages (from kubernetes>=28.1.0->chromadb) (2.0.0)\n",
      "Requirement already satisfied: durationpy>=0.7 in /Users/alice3e/.pyenv/versions/3.13.5/lib/python3.13/site-packages (from kubernetes>=28.1.0->chromadb) (0.10)\n",
      "Requirement already satisfied: cachetools<7.0,>=2.0.0 in /Users/alice3e/.pyenv/versions/3.13.5/lib/python3.13/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (6.2.4)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/alice3e/.pyenv/versions/3.13.5/lib/python3.13/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /Users/alice3e/.pyenv/versions/3.13.5/lib/python3.13/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9.1)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /Users/alice3e/.pyenv/versions/3.13.5/lib/python3.13/site-packages (from rsa<5,>=3.1.4->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.6.1)\n",
      "Requirement already satisfied: coloredlogs in /Users/alice3e/.pyenv/versions/3.13.5/lib/python3.13/site-packages (from onnxruntime>=1.14.1->chromadb) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in /Users/alice3e/.pyenv/versions/3.13.5/lib/python3.13/site-packages (from onnxruntime>=1.14.1->chromadb) (25.12.19)\n",
      "Requirement already satisfied: protobuf in /Users/alice3e/.pyenv/versions/3.13.5/lib/python3.13/site-packages (from onnxruntime>=1.14.1->chromadb) (6.33.2)\n",
      "Requirement already satisfied: sympy in /Users/alice3e/.pyenv/versions/3.13.5/lib/python3.13/site-packages (from onnxruntime>=1.14.1->chromadb) (1.14.0)\n",
      "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in /Users/alice3e/.pyenv/versions/3.13.5/lib/python3.13/site-packages (from opentelemetry-api>=1.2.0->chromadb) (8.7.1)\n",
      "Requirement already satisfied: zipp>=3.20 in /Users/alice3e/.pyenv/versions/3.13.5/lib/python3.13/site-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.23.0)\n",
      "Requirement already satisfied: googleapis-common-protos~=1.57 in /Users/alice3e/.pyenv/versions/3.13.5/lib/python3.13/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.72.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.39.1 in /Users/alice3e/.pyenv/versions/3.13.5/lib/python3.13/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.39.1)\n",
      "Requirement already satisfied: opentelemetry-proto==1.39.1 in /Users/alice3e/.pyenv/versions/3.13.5/lib/python3.13/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.39.1)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.60b1 in /Users/alice3e/.pyenv/versions/3.13.5/lib/python3.13/site-packages (from opentelemetry-sdk>=1.2.0->chromadb) (0.60b1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/alice3e/.pyenv/versions/3.13.5/lib/python3.13/site-packages (from pydantic>=1.9->chromadb) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in /Users/alice3e/.pyenv/versions/3.13.5/lib/python3.13/site-packages (from pydantic>=1.9->chromadb) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in /Users/alice3e/.pyenv/versions/3.13.5/lib/python3.13/site-packages (from pydantic>=1.9->chromadb) (0.4.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /Users/alice3e/.pyenv/versions/3.13.5/lib/python3.13/site-packages (from rich>=10.11.0->chromadb) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/alice3e/.pyenv/versions/3.13.5/lib/python3.13/site-packages (from rich>=10.11.0->chromadb) (2.19.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Users/alice3e/.pyenv/versions/3.13.5/lib/python3.13/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb) (0.1.2)\n",
      "Requirement already satisfied: huggingface-hub<2.0,>=0.16.4 in /Users/alice3e/.pyenv/versions/3.13.5/lib/python3.13/site-packages (from tokenizers>=0.13.2->chromadb) (1.2.3)\n",
      "Requirement already satisfied: filelock in /Users/alice3e/.pyenv/versions/3.13.5/lib/python3.13/site-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (3.20.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/alice3e/.pyenv/versions/3.13.5/lib/python3.13/site-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (2025.12.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.2.0 in /Users/alice3e/.pyenv/versions/3.13.5/lib/python3.13/site-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (1.2.0)\n",
      "Requirement already satisfied: shellingham in /Users/alice3e/.pyenv/versions/3.13.5/lib/python3.13/site-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (1.5.4)\n",
      "Requirement already satisfied: typer-slim in /Users/alice3e/.pyenv/versions/3.13.5/lib/python3.13/site-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (0.20.1)\n",
      "Requirement already satisfied: click>=8.0.0 in /Users/alice3e/.pyenv/versions/3.13.5/lib/python3.13/site-packages (from typer>=0.9.0->chromadb) (8.3.1)\n",
      "Requirement already satisfied: httptools>=0.6.3 in /Users/alice3e/.pyenv/versions/3.13.5/lib/python3.13/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.7.1)\n",
      "Requirement already satisfied: python-dotenv>=0.13 in /Users/alice3e/.pyenv/versions/3.13.5/lib/python3.13/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.2.1)\n",
      "Requirement already satisfied: uvloop>=0.15.1 in /Users/alice3e/.pyenv/versions/3.13.5/lib/python3.13/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.22.1)\n",
      "Requirement already satisfied: watchfiles>=0.13 in /Users/alice3e/.pyenv/versions/3.13.5/lib/python3.13/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.1.1)\n",
      "Requirement already satisfied: websockets>=10.4 in /Users/alice3e/.pyenv/versions/3.13.5/lib/python3.13/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (15.0.1)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in /Users/alice3e/.pyenv/versions/3.13.5/lib/python3.13/site-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb) (10.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /Users/alice3e/.pyenv/versions/3.13.5/lib/python3.13/site-packages (from requests-oauthlib->kubernetes>=28.1.0->chromadb) (3.3.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/alice3e/.pyenv/versions/3.13.5/lib/python3.13/site-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: mps\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import models, transforms\n",
    "from PIL import Image, ImageFile\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import chromadb  # Заменили faiss на chromadb\n",
    "from datetime import datetime\n",
    "\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "\n",
    "device = torch.device(\"mps\") if torch.backends.mps.is_available() else torch.device(\"cpu\")\n",
    "print(f\"Device: {device}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Загрузка датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Всего изображений: 12000\n",
      "\n",
      "Классы: ['Canis aureus' 'Canis familiaris' 'Canis familiaris dingo'\n",
      " 'Canis latrans' 'Canis lupus']\n",
      "\n",
      "Распределение по классам:\n",
      "scientific_name\n",
      "Canis aureus              2400\n",
      "Canis familiaris          2400\n",
      "Canis familiaris dingo    2400\n",
      "Canis latrans             2400\n",
      "Canis lupus               2400\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Загружаем CSV с информацией об изображениях\n",
    "df = pd.read_csv('../data/balanced_animals_dataset.csv')\n",
    "print(f\"Всего изображений: {len(df)}\")\n",
    "print(f\"\\nКлассы: {df['scientific_name'].unique()}\")\n",
    "print(f\"\\nРаспределение по классам:\\n{df['scientific_name'].value_counts()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Создание экстрактора эмбеддингов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmbeddingExtractor(nn.Module):\n",
    "    \"\"\"Модель для извлечения эмбеддингов из различных архитектур\"\"\"\n",
    "    \n",
    "    def __init__(self, base_model, model_type='efficientnet'):\n",
    "        super().__init__()\n",
    "        self.model_type = model_type\n",
    "        \n",
    "        if model_type == 'efficientnet':\n",
    "            # Для EfficientNet: features + avgpool\n",
    "            self.features = base_model.features\n",
    "            self.avgpool = base_model.avgpool\n",
    "        elif model_type == 'resnet':\n",
    "            # Для ResNet: все слои кроме fc\n",
    "            self.conv1 = base_model.conv1\n",
    "            self.bn1 = base_model.bn1\n",
    "            self.relu = base_model.relu\n",
    "            self.maxpool = base_model.maxpool\n",
    "            self.layer1 = base_model.layer1\n",
    "            self.layer2 = base_model.layer2\n",
    "            self.layer3 = base_model.layer3\n",
    "            self.layer4 = base_model.layer4\n",
    "            self.avgpool = base_model.avgpool\n",
    "        else:\n",
    "            raise ValueError(f\"Неподдерживаемый тип модели: {model_type}\")\n",
    "        \n",
    "    def forward(self, x):\n",
    "        if self.model_type == 'efficientnet':\n",
    "            x = self.features(x)\n",
    "            x = self.avgpool(x)\n",
    "            x = torch.flatten(x, 1)\n",
    "        elif self.model_type == 'resnet':\n",
    "            x = self.conv1(x)\n",
    "            x = self.bn1(x)\n",
    "            x = self.relu(x)\n",
    "            x = self.maxpool(x)\n",
    "            \n",
    "            x = self.layer1(x)\n",
    "            x = self.layer2(x)\n",
    "            x = self.layer3(x)\n",
    "            x = self.layer4(x)\n",
    "            \n",
    "            x = self.avgpool(x)\n",
    "            x = torch.flatten(x, 1)\n",
    "        \n",
    "        return x\n",
    "\n",
    "\n",
    "def load_embedding_extractor(checkpoint_path):\n",
    "    \"\"\"Загружает модель и создает экстрактор эмбеддингов\"\"\"\n",
    "    \n",
    "    # Загружаем checkpoint\n",
    "    checkpoint = torch.load(checkpoint_path, map_location=device)\n",
    "    params = checkpoint['params']\n",
    "    \n",
    "    print(f\"Загружена модель: {params['model']['name']}\")\n",
    "    print(f\"Количество классов: {params['model']['num_classes']}\")\n",
    "    \n",
    "    # Создаем базовую модель\n",
    "    model_name = params['model']['name']\n",
    "    num_classes = params['model']['num_classes']\n",
    "    \n",
    "    if model_name == 'efficientnet_v2_m':\n",
    "        weights = getattr(models.EfficientNet_V2_M_Weights, params['model']['pretrained'])\n",
    "        base_model = models.efficientnet_v2_m(weights=weights)\n",
    "        num_features = base_model.classifier[1].in_features\n",
    "        base_model.classifier[1] = nn.Linear(num_features, num_classes)\n",
    "        model_type = 'efficientnet'\n",
    "        \n",
    "    elif model_name == 'resnet50':\n",
    "        weights = getattr(models.ResNet50_Weights, params['model']['pretrained'])\n",
    "        base_model = models.resnet50(weights=weights)\n",
    "        num_features = base_model.fc.in_features\n",
    "        base_model.fc = nn.Linear(num_features, num_classes)\n",
    "        model_type = 'resnet'\n",
    "        \n",
    "    else:\n",
    "        raise ValueError(f\"Модель {model_name} не поддерживается. Поддерживаются: efficientnet_v2_m, resnet50\")\n",
    "    \n",
    "    # Загружаем веса\n",
    "    base_model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    \n",
    "    # Создаем экстрактор эмбеддингов (без классификационного слоя)\n",
    "    embedding_extractor = EmbeddingExtractor(base_model, model_type=model_type)\n",
    "    embedding_extractor.eval()\n",
    "    embedding_extractor = embedding_extractor.to(device)\n",
    "    \n",
    "    # Определяем размерность эмбеддинга\n",
    "    with torch.no_grad():\n",
    "        dummy_input = torch.randn(1, 3, 224, 224).to(device)\n",
    "        dummy_output = embedding_extractor(dummy_input)\n",
    "        embedding_dim = dummy_output.shape[1]\n",
    "    \n",
    "    print(f\"Размерность эмбеддинга: {embedding_dim}\")\n",
    "    print(f\"Тип модели: {model_type}\")\n",
    "    \n",
    "    return embedding_extractor, embedding_dim, checkpoint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Загружена модель: resnet50\n",
      "Количество классов: 5\n",
      "Размерность эмбеддинга: 2048\n",
      "Тип модели: resnet\n",
      "\n",
      "Маппинг классов:\n",
      "  0: Canis aureus\n",
      "  1: Canis familiaris\n",
      "  2: Canis familiaris dingo\n",
      "  3: Canis latrans\n",
      "  4: Canis lupus\n"
     ]
    }
   ],
   "source": [
    "# Загружаем модель\n",
    "model_path = Path('../models/best_model.pth')\n",
    "embedding_extractor, embedding_dim, checkpoint = load_embedding_extractor(model_path)\n",
    "\n",
    "# Извлекаем маппинги классов\n",
    "idx_to_label = checkpoint['idx_to_label']\n",
    "label_to_idx = checkpoint['label_to_idx']\n",
    "\n",
    "print(f\"\\nМаппинг классов:\")\n",
    "for idx, label in idx_to_label.items():\n",
    "    print(f\"  {idx}: {label}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Подготовка DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Создан DataLoader с 12000 изображениями\n"
     ]
    }
   ],
   "source": [
    "class ImageDataset(Dataset):\n",
    "    \"\"\"Dataset для загрузки изображений\"\"\"\n",
    "    \n",
    "    def __init__(self, dataframe, transform=None):\n",
    "        self.df = dataframe.reset_index(drop=True)\n",
    "        self.transform = transform\n",
    "        self.base_path = Path('../animal_images')\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        species = row['scientific_name'].replace(' ', '_')\n",
    "        img_path = self.base_path / species / f\"{row['uuid']}.jpg\"\n",
    "        \n",
    "        try:\n",
    "            image = Image.open(img_path).convert('RGB')\n",
    "        except Exception as e:\n",
    "            print(f\"Ошибка загрузки {img_path}: {e}\")\n",
    "            image = Image.new('RGB', (224, 224), color=(0, 0, 0))\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        # Возвращаем изображение и метаданные\n",
    "        metadata = {\n",
    "            'uuid': row['uuid'],\n",
    "            'scientific_name': row['scientific_name'],\n",
    "            'path': str(img_path.relative_to(Path('../'))),\n",
    "            'index': idx\n",
    "        }\n",
    "        \n",
    "        return image, metadata\n",
    "\n",
    "\n",
    "# Трансформации (такие же как при валидации)\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(384),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Создаем dataset и dataloader\n",
    "dataset = ImageDataset(df, transform=transform)\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=False, num_workers=0)\n",
    "\n",
    "print(f\"Создан DataLoader с {len(dataset)} изображениями\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Извлечение эмбеддингов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_embeddings(model, dataloader, device):\n",
    "    \"\"\"Извлекает эмбеддинги для всех изображений\"\"\"\n",
    "    \n",
    "    all_embeddings = []\n",
    "    all_metadata = []\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, metadata_batch in tqdm(dataloader, desc=\"Извлечение эмбеддингов\"):\n",
    "            images = images.to(device)\n",
    "            \n",
    "            # Получаем эмбеддинги\n",
    "            embeddings = model(images)\n",
    "            \n",
    "            embeddings_np = embeddings.cpu().numpy().astype(np.float32)\n",
    "            embeddings_np = np.ascontiguousarray(embeddings_np)\n",
    "            all_embeddings.append(embeddings_np)\n",
    "            \n",
    "            # Сохраняем метаданные\n",
    "            for i in range(len(metadata_batch['uuid'])):\n",
    "                meta = {\n",
    "                    'uuid': metadata_batch['uuid'][i],\n",
    "                    'scientific_name': metadata_batch['scientific_name'][i],\n",
    "                    'path': metadata_batch['path'][i],\n",
    "                    'embedding_index': len(all_metadata)\n",
    "                }\n",
    "                all_metadata.append(meta)\n",
    "    \n",
    "    # Объединяем все эмбеддинги\n",
    "    all_embeddings = np.vstack(all_embeddings)\n",
    "    all_embeddings = np.ascontiguousarray(all_embeddings, dtype=np.float32)\n",
    "    \n",
    "    print(f\"\\nИзвлечено эмбеддингов: {all_embeddings.shape}\")\n",
    "    print(f\"Метаданных: {len(all_metadata)}\")\n",
    "    print(f\"Тип данных: {all_embeddings.dtype}\")\n",
    "    print(f\"Contiguous: {all_embeddings.flags['C_CONTIGUOUS']}\")\n",
    "    \n",
    "    return all_embeddings, all_metadata\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Извлечение эмбеддингов: 100%|██████████| 375/375 [01:22<00:00,  4.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Извлечено эмбеддингов: (12000, 2048)\n",
      "Метаданных: 12000\n",
      "Тип данных: float32\n",
      "Contiguous: True\n",
      "\n",
      "Форма массива эмбеддингов: (12000, 2048)\n",
      "Тип данных: float32\n",
      "\n",
      "Пример метаданных первого изображения:\n",
      "{\n",
      "  \"uuid\": \"710acdf3-5470-44ca-a1ac-32fb42c95b70\",\n",
      "  \"scientific_name\": \"Canis aureus\",\n",
      "  \"path\": \"animal_images/Canis_aureus/710acdf3-5470-44ca-a1ac-32fb42c95b70.jpg\",\n",
      "  \"embedding_index\": 0\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Извлекаем эмбеддинги\n",
    "embeddings, metadata = extract_embeddings(embedding_extractor, dataloader, device)\n",
    "\n",
    "print(f\"\\nФорма массива эмбеддингов: {embeddings.shape}\")\n",
    "print(f\"Тип данных: {embeddings.dtype}\")\n",
    "print(f\"\\nПример метаданных первого изображения:\")\n",
    "print(json.dumps(metadata[0], indent=2, ensure_ascii=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Построение chroma индекса"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_chromadb_collection(embeddings, metadata, collection_name=\"animal_embeddings\"):\n",
    "    \"\"\"Строит ChromaDB коллекцию для поиска похожих векторов\n",
    "    \n",
    "    Args:\n",
    "        embeddings: numpy array с эмбеддингами (n_samples, embedding_dim)\n",
    "        metadata: список словарей с метаданными для каждого изображения\n",
    "        collection_name: название коллекции\n",
    "    \n",
    "    Returns:\n",
    "        client: ChromaDB клиент\n",
    "        collection: ChromaDB коллекция\n",
    "    \"\"\"\n",
    "    \n",
    "    print(f\"Создание ChromaDB коллекции '{collection_name}'...\")\n",
    "    \n",
    "    # Создаем persistent клиент (сохраняется на диск)\n",
    "    chroma_path = Path('../embeddings/chromadb')\n",
    "    chroma_path.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    client = chromadb.PersistentClient(path=str(chroma_path))\n",
    "    \n",
    "    # Удаляем коллекцию если существует (для чистого старта)\n",
    "    try:\n",
    "        client.delete_collection(name=collection_name)\n",
    "        print(\"Старая коллекция удалена\")\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    # Создаем новую коллекцию с косинусным расстоянием\n",
    "    collection = client.create_collection(\n",
    "        name=collection_name,\n",
    "        metadata={\"hnsw:space\": \"cosine\"}  # cosine, l2, или ip\n",
    "    )\n",
    "    \n",
    "    # Подготавливаем данные для ChromaDB\n",
    "    ids = [meta['uuid'] for meta in metadata]\n",
    "    embeddings_list = embeddings.tolist()\n",
    "    \n",
    "    # Подготавливаем метаданные (ChromaDB требует строковые значения)\n",
    "    metadatas = [\n",
    "        {\n",
    "            'scientific_name': meta['scientific_name'],\n",
    "            'path': meta['path'],\n",
    "            'embedding_index': str(meta['embedding_index'])\n",
    "        }\n",
    "        for meta in metadata\n",
    "    ]\n",
    "    \n",
    "    # Добавляем данные батчами (ChromaDB рекомендует батчи ~40000)\n",
    "    batch_size = 1000\n",
    "    num_batches = (len(ids) + batch_size - 1) // batch_size\n",
    "    \n",
    "    print(f\"Добавление {len(ids)} векторов в {num_batches} батчах...\")\n",
    "    \n",
    "    for i in tqdm(range(0, len(ids), batch_size), desc=\"Загрузка в ChromaDB\"):\n",
    "        batch_end = min(i + batch_size, len(ids))\n",
    "        \n",
    "        collection.add(\n",
    "            ids=ids[i:batch_end],\n",
    "            embeddings=embeddings_list[i:batch_end],\n",
    "            metadatas=metadatas[i:batch_end]\n",
    "        )\n",
    "    \n",
    "    print(f\"✓ Коллекция создана. Количество векторов: {collection.count()}\")\n",
    "    \n",
    "    return client, collection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Создание ChromaDB коллекции 'animal_embeddings'...\n",
      "Старая коллекция удалена\n",
      "Добавление 12000 векторов в 12 батчах...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Загрузка в ChromaDB: 100%|██████████| 12/12 [00:07<00:00,  1.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Коллекция создана. Количество векторов: 12000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Строим ChromaDB коллекцию\n",
    "client, collection = build_chromadb_collection(embeddings, metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Тестирование поиска"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_search(collection, metadata, test_idx=0, k=10):\n",
    "    \"\"\"Тестирует поиск похожих изображений в ChromaDB\"\"\"\n",
    "    \n",
    "    # Получаем UUID тестового изображения\n",
    "    query_uuid = metadata[test_idx]['uuid']\n",
    "    \n",
    "    print(f\"\\nТестовое изображение (индекс {test_idx}):\")\n",
    "    print(f\"  UUID: {metadata[test_idx]['uuid']}\")\n",
    "    print(f\"  Класс: {metadata[test_idx]['scientific_name']}\")\n",
    "    print(f\"  Путь: {metadata[test_idx]['path']}\")\n",
    "    \n",
    "    # Получаем эмбеддинг из коллекции\n",
    "    query_result = collection.get(\n",
    "        ids=[query_uuid],\n",
    "        include=['embeddings']\n",
    "    )\n",
    "    \n",
    "    query_embedding = query_result['embeddings'][0]\n",
    "    \n",
    "    # Ищем k ближайших соседей\n",
    "    results = collection.query(\n",
    "        query_embeddings=[query_embedding],\n",
    "        n_results=k,\n",
    "        include=['metadatas', 'distances']\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nТоп-{k} похожих изображений:\")\n",
    "    for i, (uuid, distance, meta) in enumerate(zip(\n",
    "        results['ids'][0], \n",
    "        results['distances'][0], \n",
    "        results['metadatas'][0]\n",
    "    )):\n",
    "        # Для косинусного расстояния: similarity = 1 - distance\n",
    "        similarity = (1 - distance) * 100\n",
    "        print(f\"  {i+1}. Похожесть: {similarity:.2f}% | Класс: {meta['scientific_name']} | UUID: {uuid}\")\n",
    "    \n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "ТЕСТ 1: Первое изображение\n",
      "================================================================================\n",
      "\n",
      "Тестовое изображение (индекс 0):\n",
      "  UUID: 710acdf3-5470-44ca-a1ac-32fb42c95b70\n",
      "  Класс: Canis aureus\n",
      "  Путь: animal_images/Canis_aureus/710acdf3-5470-44ca-a1ac-32fb42c95b70.jpg\n",
      "\n",
      "Топ-10 похожих изображений:\n",
      "  1. Похожесть: 100.00% | Класс: Canis aureus | UUID: 710acdf3-5470-44ca-a1ac-32fb42c95b70\n",
      "  2. Похожесть: 91.60% | Класс: Canis aureus | UUID: 06a9b4ca-e660-4bd4-906b-c88f88bd52b4\n",
      "  3. Похожесть: 89.23% | Класс: Canis aureus | UUID: e7e91bf5-7605-4385-bca1-b4853091b915\n",
      "  4. Похожесть: 88.40% | Класс: Canis aureus | UUID: f1d1451d-0cc9-4ce5-ab5a-be44112b5cfa\n",
      "  5. Похожесть: 88.38% | Класс: Canis aureus | UUID: 8db57231-ade9-44f3-85d3-ae9da509092c\n",
      "  6. Похожесть: 88.31% | Класс: Canis aureus | UUID: 2bc7c25f-8931-4f48-a534-0ad99b39aaee\n",
      "  7. Похожесть: 88.30% | Класс: Canis aureus | UUID: 63bebc7b-c974-44d4-8cb4-2e34fc60eb3f\n",
      "  8. Похожесть: 87.84% | Класс: Canis aureus | UUID: 8874bd71-ff6c-4bd2-b9de-04a27426b359\n",
      "  9. Похожесть: 87.63% | Класс: Canis aureus | UUID: c20fec3b-0eb5-46ee-82f3-52c39d8b2abf\n",
      "  10. Похожесть: 87.60% | Класс: Canis aureus | UUID: a877d121-bac2-4937-87e5-f420bbe3471c\n",
      "\n",
      "================================================================================\n",
      "ТЕСТ 2: Случайное изображение\n",
      "================================================================================\n",
      "\n",
      "Тестовое изображение (индекс 1583):\n",
      "  UUID: f4e5afce-4d24-4a35-b696-4ef5322cb87f\n",
      "  Класс: Canis aureus\n",
      "  Путь: animal_images/Canis_aureus/f4e5afce-4d24-4a35-b696-4ef5322cb87f.jpg\n",
      "\n",
      "Топ-10 похожих изображений:\n",
      "  1. Похожесть: 100.00% | Класс: Canis aureus | UUID: f4e5afce-4d24-4a35-b696-4ef5322cb87f\n",
      "  2. Похожесть: 88.30% | Класс: Canis aureus | UUID: 03a5c1d1-98ea-44c4-a7ba-f6c6a5994fc6\n",
      "  3. Похожесть: 83.01% | Класс: Canis familiaris dingo | UUID: d128f8b5-9d9d-46e1-8e3b-b8efe4c8a409\n",
      "  4. Похожесть: 80.85% | Класс: Canis aureus | UUID: ffc1a61f-f48f-4ecb-b634-a815a1440686\n",
      "  5. Похожесть: 80.17% | Класс: Canis familiaris dingo | UUID: 43891b83-3938-4a6d-b7b2-e6ef2b86ae15\n",
      "  6. Похожесть: 80.02% | Класс: Canis lupus | UUID: 39fadfde-dc8b-4d2d-98f2-e7955cfa6f21\n",
      "  7. Похожесть: 79.96% | Класс: Canis familiaris dingo | UUID: 5896eb2e-9daa-47ae-a0f6-a5fc19d0d0c0\n",
      "  8. Похожесть: 79.82% | Класс: Canis latrans | UUID: 9176cab6-24fc-4db0-a3b9-3ffcfb32a369\n",
      "  9. Похожесть: 79.61% | Класс: Canis lupus | UUID: 296e7261-a557-4041-ab75-285b580a689a\n",
      "  10. Похожесть: 79.58% | Класс: Canis familiaris | UUID: 2a315951-5ad8-4f84-8258-b96aae779782\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'ids': [['f4e5afce-4d24-4a35-b696-4ef5322cb87f',\n",
       "   '03a5c1d1-98ea-44c4-a7ba-f6c6a5994fc6',\n",
       "   'd128f8b5-9d9d-46e1-8e3b-b8efe4c8a409',\n",
       "   'ffc1a61f-f48f-4ecb-b634-a815a1440686',\n",
       "   '43891b83-3938-4a6d-b7b2-e6ef2b86ae15',\n",
       "   '39fadfde-dc8b-4d2d-98f2-e7955cfa6f21',\n",
       "   '5896eb2e-9daa-47ae-a0f6-a5fc19d0d0c0',\n",
       "   '9176cab6-24fc-4db0-a3b9-3ffcfb32a369',\n",
       "   '296e7261-a557-4041-ab75-285b580a689a',\n",
       "   '2a315951-5ad8-4f84-8258-b96aae779782']],\n",
       " 'embeddings': None,\n",
       " 'documents': None,\n",
       " 'uris': None,\n",
       " 'included': ['metadatas', 'distances'],\n",
       " 'data': None,\n",
       " 'metadatas': [[{'embedding_index': '1583',\n",
       "    'scientific_name': 'Canis aureus',\n",
       "    'path': 'animal_images/Canis_aureus/f4e5afce-4d24-4a35-b696-4ef5322cb87f.jpg'},\n",
       "   {'scientific_name': 'Canis aureus',\n",
       "    'embedding_index': '2266',\n",
       "    'path': 'animal_images/Canis_aureus/03a5c1d1-98ea-44c4-a7ba-f6c6a5994fc6.jpg'},\n",
       "   {'embedding_index': '6033',\n",
       "    'path': 'animal_images/Canis_familiaris_dingo/d128f8b5-9d9d-46e1-8e3b-b8efe4c8a409.jpg',\n",
       "    'scientific_name': 'Canis familiaris dingo'},\n",
       "   {'path': 'animal_images/Canis_aureus/ffc1a61f-f48f-4ecb-b634-a815a1440686.jpg',\n",
       "    'embedding_index': '1842',\n",
       "    'scientific_name': 'Canis aureus'},\n",
       "   {'scientific_name': 'Canis familiaris dingo',\n",
       "    'embedding_index': '6584',\n",
       "    'path': 'animal_images/Canis_familiaris_dingo/43891b83-3938-4a6d-b7b2-e6ef2b86ae15.jpg'},\n",
       "   {'path': 'animal_images/Canis_lupus/39fadfde-dc8b-4d2d-98f2-e7955cfa6f21.jpg',\n",
       "    'embedding_index': '10599',\n",
       "    'scientific_name': 'Canis lupus'},\n",
       "   {'scientific_name': 'Canis familiaris dingo',\n",
       "    'path': 'animal_images/Canis_familiaris_dingo/5896eb2e-9daa-47ae-a0f6-a5fc19d0d0c0.jpg',\n",
       "    'embedding_index': '5744'},\n",
       "   {'path': 'animal_images/Canis_latrans/9176cab6-24fc-4db0-a3b9-3ffcfb32a369.jpg',\n",
       "    'embedding_index': '9231',\n",
       "    'scientific_name': 'Canis latrans'},\n",
       "   {'scientific_name': 'Canis lupus',\n",
       "    'embedding_index': '9727',\n",
       "    'path': 'animal_images/Canis_lupus/296e7261-a557-4041-ab75-285b580a689a.jpg'},\n",
       "   {'scientific_name': 'Canis familiaris',\n",
       "    'embedding_index': '4265',\n",
       "    'path': 'animal_images/Canis_familiaris/2a315951-5ad8-4f84-8258-b96aae779782.jpg'}]],\n",
       " 'distances': [[7.748603820800781e-07,\n",
       "   0.11698853969573975,\n",
       "   0.16990292072296143,\n",
       "   0.19148606061935425,\n",
       "   0.19831198453903198,\n",
       "   0.1998109221458435,\n",
       "   0.20038002729415894,\n",
       "   0.20184540748596191,\n",
       "   0.20385140180587769,\n",
       "   0.20420622825622559]]}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Тестируем поиск на нескольких примерах\n",
    "print(\"=\" * 80)\n",
    "print(\"ТЕСТ 1: Первое изображение\")\n",
    "print(\"=\" * 80)\n",
    "test_search(collection, metadata, test_idx=0, k=10)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"ТЕСТ 2: Случайное изображение\")\n",
    "print(\"=\" * 80)\n",
    "random_idx = np.random.randint(0, len(metadata))\n",
    "test_search(collection, metadata, test_idx=random_idx, k=10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Сохранение индекса и метаданных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ ChromaDB сохранен в: ../embeddings/chromadb\n",
      "✓ Метаданные сохранены: ../embeddings/image_metadata.json\n",
      "✓ Эмбеддинги сохранены: ../embeddings/embeddings.npy\n",
      "\n",
      "Все файлы сохранены в директории: ../embeddings\n",
      "Размер ChromaDB: 173.46 MB\n",
      "Размер метаданных: 2680.16 KB\n",
      "Размер эмбеддингов: 93.75 MB\n"
     ]
    }
   ],
   "source": [
    "# Создаем директорию для сохранения\n",
    "embeddings_dir = Path('../embeddings')\n",
    "embeddings_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# ChromaDB уже сохранен в persistent mode\n",
    "print(f\"✓ ChromaDB сохранен в: {embeddings_dir / 'chromadb'}\")\n",
    "\n",
    "# Сохраняем метаданные\n",
    "metadata_dict = {\n",
    "    'images': metadata,\n",
    "    'metadata': {\n",
    "        'total_images': len(metadata),\n",
    "        'embedding_dim': embedding_dim,\n",
    "        'model': checkpoint['params']['model']['name'],\n",
    "        'use_cosine_similarity': True,\n",
    "        'created_at': datetime.now().isoformat(),\n",
    "        'classes': list(idx_to_label.values()),\n",
    "        'collection_name': 'animal_embeddings'\n",
    "    }\n",
    "}\n",
    "\n",
    "metadata_path = embeddings_dir / 'image_metadata.json'\n",
    "with open(metadata_path, 'w', encoding='utf-8') as f:\n",
    "    json.dump(metadata_dict, f, indent=2, ensure_ascii=False)\n",
    "print(f\"✓ Метаданные сохранены: {metadata_path}\")\n",
    "\n",
    "# Опционально: сохраняем сами эмбеддинги (для анализа)\n",
    "embeddings_path = embeddings_dir / 'embeddings.npy'\n",
    "np.save(embeddings_path, embeddings)\n",
    "print(f\"✓ Эмбеддинги сохранены: {embeddings_path}\")\n",
    "\n",
    "# Статистика размеров\n",
    "import shutil\n",
    "chroma_size = sum(f.stat().st_size for f in (embeddings_dir / 'chromadb').rglob('*') if f.is_file())\n",
    "print(f\"\\nВсе файлы сохранены в директории: {embeddings_dir}\")\n",
    "print(f\"Размер ChromaDB: {chroma_size / 1024 / 1024:.2f} MB\")\n",
    "print(f\"Размер метаданных: {metadata_path.stat().st_size / 1024:.2f} KB\")\n",
    "print(f\"Размер эмбеддингов: {embeddings_path.stat().st_size / 1024 / 1024:.2f} MB\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Проверка загрузки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Проверка загрузки ChromaDB...\n",
      "✓ ChromaDB загружен. Количество векторов: 12000\n",
      "✓ Метаданные загружены. Количество изображений: 12000\n",
      "✓ Эмбеддинги загружены. Форма: (12000, 2048)\n",
      "\n",
      "✅ Все файлы успешно сохранены и загружены!\n",
      "\n",
      "================================================================================\n",
      "ТЕСТ: Поиск в загруженной коллекции\n",
      "================================================================================\n",
      "\n",
      "Тестовое изображение (индекс 100):\n",
      "  UUID: e14cf0ed-919f-4d09-8f9a-eff023047033\n",
      "  Класс: Canis aureus\n",
      "  Путь: animal_images/Canis_aureus/e14cf0ed-919f-4d09-8f9a-eff023047033.jpg\n",
      "\n",
      "Топ-5 похожих изображений:\n",
      "  1. Похожесть: 100.00% | Класс: Canis aureus | UUID: e14cf0ed-919f-4d09-8f9a-eff023047033\n",
      "  2. Похожесть: 78.75% | Класс: Canis lupus | UUID: 7661b946-70c0-4322-a0ae-74b7970785ac\n",
      "  3. Похожесть: 78.72% | Класс: Canis latrans | UUID: 9d367e2a-9dfe-4e70-88f3-04b66d49170a\n",
      "  4. Похожесть: 78.29% | Класс: Canis lupus | UUID: be2d4b4c-6fae-4b6c-a505-803e3e694701\n",
      "  5. Похожесть: 78.07% | Класс: Canis latrans | UUID: 0a864fe7-868c-483f-97a9-fe7ad7a0c39b\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'ids': [['e14cf0ed-919f-4d09-8f9a-eff023047033',\n",
       "   '7661b946-70c0-4322-a0ae-74b7970785ac',\n",
       "   '9d367e2a-9dfe-4e70-88f3-04b66d49170a',\n",
       "   'be2d4b4c-6fae-4b6c-a505-803e3e694701',\n",
       "   '0a864fe7-868c-483f-97a9-fe7ad7a0c39b']],\n",
       " 'embeddings': None,\n",
       " 'documents': None,\n",
       " 'uris': None,\n",
       " 'included': ['metadatas', 'distances'],\n",
       " 'data': None,\n",
       " 'metadatas': [[{'embedding_index': '100',\n",
       "    'scientific_name': 'Canis aureus',\n",
       "    'path': 'animal_images/Canis_aureus/e14cf0ed-919f-4d09-8f9a-eff023047033.jpg'},\n",
       "   {'path': 'animal_images/Canis_lupus/7661b946-70c0-4322-a0ae-74b7970785ac.jpg',\n",
       "    'scientific_name': 'Canis lupus',\n",
       "    'embedding_index': '9731'},\n",
       "   {'embedding_index': '8928',\n",
       "    'scientific_name': 'Canis latrans',\n",
       "    'path': 'animal_images/Canis_latrans/9d367e2a-9dfe-4e70-88f3-04b66d49170a.jpg'},\n",
       "   {'embedding_index': '11334',\n",
       "    'path': 'animal_images/Canis_lupus/be2d4b4c-6fae-4b6c-a505-803e3e694701.jpg',\n",
       "    'scientific_name': 'Canis lupus'},\n",
       "   {'path': 'animal_images/Canis_latrans/0a864fe7-868c-483f-97a9-fe7ad7a0c39b.jpg',\n",
       "    'scientific_name': 'Canis latrans',\n",
       "    'embedding_index': '8662'}]],\n",
       " 'distances': [[-2.384185791015625e-07,\n",
       "   0.2125360369682312,\n",
       "   0.21283388137817383,\n",
       "   0.21711128950119019,\n",
       "   0.21933400630950928]]}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Проверяем, что ChromaDB можно загрузить обратно\n",
    "print(\"Проверка загрузки ChromaDB...\")\n",
    "\n",
    "# Загружаем существующий клиент\n",
    "loaded_client = chromadb.PersistentClient(path=str(embeddings_dir / 'chromadb'))\n",
    "loaded_collection = loaded_client.get_collection(name=\"animal_embeddings\")\n",
    "print(f\"✓ ChromaDB загружен. Количество векторов: {loaded_collection.count()}\")\n",
    "\n",
    "with open(metadata_path, 'r', encoding='utf-8') as f:\n",
    "    loaded_metadata = json.load(f)\n",
    "print(f\"✓ Метаданные загружены. Количество изображений: {loaded_metadata['metadata']['total_images']}\")\n",
    "\n",
    "loaded_embeddings = np.load(embeddings_path)\n",
    "print(f\"✓ Эмбеддинги загружены. Форма: {loaded_embeddings.shape}\")\n",
    "\n",
    "print(\"\\n✅ Все файлы успешно сохранены и загружены!\")\n",
    "\n",
    "# Тестовый поиск на загруженной коллекции\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"ТЕСТ: Поиск в загруженной коллекции\")\n",
    "print(\"=\" * 80)\n",
    "test_idx = 100\n",
    "test_search(loaded_collection, loaded_metadata['images'], test_idx=test_idx, k=5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Статистика и визуализация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Распределение изображений по классам:\n",
      "  Canis aureus: 2400 изображений\n",
      "  Canis familiaris: 2400 изображений\n",
      "  Canis familiaris dingo: 2400 изображений\n",
      "  Canis latrans: 2400 изображений\n",
      "  Canis lupus: 2400 изображений\n",
      "\n",
      "Всего классов: 5\n",
      "Всего изображений: 12000\n"
     ]
    }
   ],
   "source": [
    "# Статистика по классам\n",
    "class_counts = {}\n",
    "for meta in metadata:\n",
    "    class_name = meta['scientific_name']\n",
    "    class_counts[class_name] = class_counts.get(class_name, 0) + 1\n",
    "\n",
    "print(\"Распределение изображений по классам:\")\n",
    "for class_name, count in sorted(class_counts.items()):\n",
    "    print(f\"  {class_name}: {count} изображений\")\n",
    "\n",
    "print(f\"\\nВсего классов: {len(class_counts)}\")\n",
    "print(f\"Всего изображений: {sum(class_counts.values())}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
