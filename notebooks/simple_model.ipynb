{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2da3530f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: mps\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "from dvclive import Live\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import models, transforms\n",
    "from PIL import Image, ImageFile\n",
    "from tqdm import tqdm\n",
    "import yaml\n",
    "\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "\n",
    "device = torch.device(\"mps\") if torch.backends.mps.is_available() else torch.device(\"cpu\")\n",
    "print(f\"Device: {device}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "19f3b3eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters:\n",
      "augmentation:\n",
      "  brightness: 0.2\n",
      "  contrast: 0.2\n",
      "  crop_size: 256\n",
      "  resize: 256\n",
      "data:\n",
      "  random_state: 42\n",
      "  train_test_split: 0.2\n",
      "model:\n",
      "  name: resnet50\n",
      "  num_classes: 5\n",
      "  pretrained: IMAGENET1K_V1\n",
      "scheduler:\n",
      "  gamma: 0.1\n",
      "  step_size: 5\n",
      "training:\n",
      "  batch_size: 32\n",
      "  learning_rate: 0.001\n",
      "  num_epochs: 20\n",
      "  optimizer: Adam\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open('../params.yaml', 'r') as f:\n",
    "    params = yaml.safe_load(f)\n",
    "\n",
    "print(\"Parameters:\")\n",
    "print(yaml.dump(params, default_flow_style=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d6974ff1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (12000, 6)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('../data/balanced_animals_dataset.csv')\n",
    "print(f\"Dataset shape: {df.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "12ba29a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_to_idx = {label: idx for idx, label in enumerate(df['scientific_name'].unique())}\n",
    "idx_to_label = {idx: label for label, idx in label_to_idx.items()}\n",
    "df['label'] = df['scientific_name'].map(label_to_idx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "46a84d20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 9600, Val: 2400\n"
     ]
    }
   ],
   "source": [
    "train_df, val_df = train_test_split(\n",
    "    df, \n",
    "    test_size=params['data']['train_test_split'], \n",
    "    stratify=df['label'], \n",
    "    random_state=params['data']['random_state']\n",
    ")\n",
    "\n",
    "print(f\"Train: {len(train_df)}, Val: {len(val_df)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9e973b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AnimalDataset(Dataset):\n",
    "    def __init__(self, dataframe, transform=None):\n",
    "        self.df = dataframe.reset_index(drop=True)\n",
    "        self.transform = transform\n",
    "        self.base_path = Path('../animal_images')\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        species = row['scientific_name'].replace(' ', '_')\n",
    "        img_path = self.base_path / species / f\"{row['uuid']}.jpg\"\n",
    "        \n",
    "        try:\n",
    "            image = Image.open(img_path).convert('RGB')\n",
    "        except Exception:\n",
    "            image = Image.new('RGB', (224, 224), color=(0, 0, 0))\n",
    "            \n",
    "        label = row['label']\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            \n",
    "        return image, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "60b59aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize(params['augmentation']['resize']),\n",
    "    transforms.RandomCrop(params['augmentation']['crop_size']),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ColorJitter(\n",
    "        brightness=params['augmentation']['brightness'],\n",
    "        contrast=params['augmentation']['contrast'],\n",
    "        saturation=params['augmentation']['contrast']\n",
    "    ),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize(params['augmentation']['resize']),\n",
    "    transforms.CenterCrop(params['augmentation']['crop_size']),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "087f23d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = AnimalDataset(train_df, transform=train_transform)\n",
    "val_dataset = AnimalDataset(val_df, transform=val_transform)\n",
    "\n",
    "batch_size = params['training']['batch_size']\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9d20f037",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: resnet50\n",
      "Trainable parameters: 10,245\n"
     ]
    }
   ],
   "source": [
    "if params['model']['name'] == 'resnet50':\n",
    "    weights = getattr(models.ResNet50_Weights, params['model']['pretrained'])\n",
    "    model = models.resnet50(weights=weights)\n",
    "    num_features = model.fc.in_features\n",
    "    model.fc = nn.Linear(num_features, params['model']['num_classes'])\n",
    "    \n",
    "elif params['model']['name'] == 'resnet101':\n",
    "    weights = getattr(models.ResNet101_Weights, params['model']['pretrained'])\n",
    "    model = models.resnet101(weights=weights)\n",
    "    num_features = model.fc.in_features\n",
    "    model.fc = nn.Linear(num_features, params['model']['num_classes'])\n",
    "    \n",
    "elif params['model']['name'] == 'efficientnet_v2_m':\n",
    "    weights = getattr(models.EfficientNet_V2_M_Weights, params['model']['pretrained'])\n",
    "    model = models.efficientnet_v2_m(weights=weights)\n",
    "    num_features = model.classifier[1].in_features\n",
    "    model.classifier[1] = nn.Linear(num_features, params['model']['num_classes'])\n",
    "    \n",
    "elif params['model']['name'] == 'convnext_base':\n",
    "    weights = getattr(models.ConvNeXt_Base_Weights, params['model']['pretrained'])\n",
    "    model = models.convnext_base(weights=weights)\n",
    "    num_features = model.classifier[2].in_features\n",
    "    model.classifier[2] = nn.Linear(num_features, params['model']['num_classes'])\n",
    "    \n",
    "elif params['model']['name'] == 'vit_b_16':\n",
    "    weights = getattr(models.ViT_B_16_Weights, params['model']['pretrained'])\n",
    "    model = models.vit_b_16(weights=weights)\n",
    "    num_features = model.heads.head.in_features\n",
    "    model.heads.head = nn.Linear(num_features, params['model']['num_classes'])\n",
    "\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Разморозить последний слой\n",
    "if 'efficientnet' in params['model']['name']:\n",
    "    for param in model.classifier.parameters():\n",
    "        param.requires_grad = True\n",
    "elif 'convnext' in params['model']['name']:\n",
    "    for param in model.classifier.parameters():\n",
    "        param.requires_grad = True\n",
    "elif 'vit' in params['model']['name']:\n",
    "    for param in model.heads.parameters():\n",
    "        param.requires_grad = True\n",
    "else:\n",
    "    for param in model.fc.parameters():\n",
    "        param.requires_grad = True\n",
    "\n",
    "model = model.to(device)\n",
    "print(f\"Model: {params['model']['name']}\")\n",
    "print(f\"Trainable parameters: {sum(p.numel() for p in model.parameters() if p.requires_grad):,}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e63049f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Получить параметры для обучения в зависимости от модели\n",
    "if 'efficientnet' in params['model']['name']:\n",
    "    trainable_params = model.classifier.parameters()\n",
    "elif 'convnext' in params['model']['name']:\n",
    "    trainable_params = model.classifier.parameters()\n",
    "elif 'vit' in params['model']['name']:\n",
    "    trainable_params = model.heads.parameters()\n",
    "else:\n",
    "    trainable_params = model.fc.parameters()\n",
    "\n",
    "optimizer = optim.Adam(trainable_params, lr=params['training']['learning_rate'])\n",
    "scheduler = optim.lr_scheduler.StepLR(\n",
    "    optimizer, \n",
    "    step_size=params['scheduler']['step_size'], \n",
    "    gamma=params['scheduler']['gamma']\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "61083b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, loader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for images, labels in tqdm(loader, desc=\"Training\"):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "    \n",
    "    return running_loss / len(loader), 100. * correct / total\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dcd78141",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, loader, criterion, device):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(loader, desc=\"Validation\"):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "            \n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    return running_loss / len(loader), 100. * correct / total, np.array(all_preds), np.array(all_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2804810a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 300/300 [01:29<00:00,  3.35it/s]\n",
      "Validation: 100%|██████████| 75/75 [00:17<00:00,  4.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.1636, Train Acc: 54.07%\n",
      "Val Loss: 0.9429, Val Acc: 63.04%\n",
      "Best model saved: 63.04%\n",
      "\n",
      "Epoch 2/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 300/300 [01:25<00:00,  3.49it/s]\n",
      "Validation: 100%|██████████| 75/75 [00:17<00:00,  4.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.9890, Train Acc: 62.26%\n",
      "Val Loss: 0.9447, Val Acc: 64.92%\n",
      "Best model saved: 64.92%\n",
      "\n",
      "Epoch 3/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 300/300 [01:24<00:00,  3.56it/s]\n",
      "Validation: 100%|██████████| 75/75 [00:17<00:00,  4.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.9542, Train Acc: 63.24%\n",
      "Val Loss: 0.9301, Val Acc: 65.33%\n",
      "Best model saved: 65.33%\n",
      "\n",
      "Epoch 4/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 300/300 [01:23<00:00,  3.58it/s]\n",
      "Validation: 100%|██████████| 75/75 [00:17<00:00,  4.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.9495, Train Acc: 63.54%\n",
      "Val Loss: 0.9090, Val Acc: 66.17%\n",
      "Best model saved: 66.17%\n",
      "\n",
      "Epoch 5/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 300/300 [01:23<00:00,  3.57it/s]\n",
      "Validation: 100%|██████████| 75/75 [00:17<00:00,  4.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.9405, Train Acc: 64.27%\n",
      "Val Loss: 0.9362, Val Acc: 64.75%\n",
      "\n",
      "Epoch 6/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 300/300 [01:24<00:00,  3.54it/s]\n",
      "Validation: 100%|██████████| 75/75 [00:17<00:00,  4.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.8585, Train Acc: 67.33%\n",
      "Val Loss: 0.8811, Val Acc: 67.46%\n",
      "Best model saved: 67.46%\n",
      "\n",
      "Epoch 7/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 300/300 [01:23<00:00,  3.58it/s]\n",
      "Validation: 100%|██████████| 75/75 [00:17<00:00,  4.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.8630, Train Acc: 66.84%\n",
      "Val Loss: 0.8743, Val Acc: 67.58%\n",
      "Best model saved: 67.58%\n",
      "\n",
      "Epoch 8/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 300/300 [01:23<00:00,  3.59it/s]\n",
      "Validation: 100%|██████████| 75/75 [00:17<00:00,  4.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.8536, Train Acc: 67.76%\n",
      "Val Loss: 0.8687, Val Acc: 68.00%\n",
      "Best model saved: 68.00%\n",
      "\n",
      "Epoch 9/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 300/300 [01:23<00:00,  3.59it/s]\n",
      "Validation: 100%|██████████| 75/75 [00:17<00:00,  4.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.8619, Train Acc: 66.96%\n",
      "Val Loss: 0.8694, Val Acc: 66.96%\n",
      "\n",
      "Epoch 10/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 300/300 [01:24<00:00,  3.53it/s]\n",
      "Validation: 100%|██████████| 75/75 [00:18<00:00,  4.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.8560, Train Acc: 67.64%\n",
      "Val Loss: 0.8783, Val Acc: 67.33%\n",
      "\n",
      "Epoch 11/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  77%|███████▋  | 231/300 [01:07<00:20,  3.42it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 12\u001b[39m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[32m     10\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch+\u001b[32m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_epochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m     train_loss, train_acc = \u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     15\u001b[39m     val_loss, val_acc, val_preds, val_labels = validate(\n\u001b[32m     16\u001b[39m         model, val_loader, criterion, device\n\u001b[32m     17\u001b[39m     )\n\u001b[32m     19\u001b[39m     live.log_metric(\u001b[33m'\u001b[39m\u001b[33mtrain/loss\u001b[39m\u001b[33m'\u001b[39m, train_loss)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[24]\u001b[39m\u001b[32m, line 16\u001b[39m, in \u001b[36mtrain_epoch\u001b[39m\u001b[34m(model, loader, criterion, optimizer, device)\u001b[39m\n\u001b[32m     13\u001b[39m loss.backward()\n\u001b[32m     14\u001b[39m optimizer.step()\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m running_loss += \u001b[43mloss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     17\u001b[39m _, predicted = outputs.max(\u001b[32m1\u001b[39m)\n\u001b[32m     18\u001b[39m total += labels.size(\u001b[32m0\u001b[39m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "num_epochs = params['training']['num_epochs']\n",
    "best_val_acc = 0.0\n",
    "Path('../models').mkdir(exist_ok=True)\n",
    "\n",
    "with Live(dir='../dvclive', save_dvc_exp=True) as live:\n",
    "    \n",
    "    live.log_params(params)\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n",
    "        \n",
    "        train_loss, train_acc = train_epoch(\n",
    "            model, train_loader, criterion, optimizer, device\n",
    "        )\n",
    "        val_loss, val_acc, val_preds, val_labels = validate(\n",
    "            model, val_loader, criterion, device\n",
    "        )\n",
    "        \n",
    "        live.log_metric('train/loss', train_loss)\n",
    "        live.log_metric('train/accuracy', train_acc)\n",
    "        live.log_metric('val/loss', val_loss)\n",
    "        live.log_metric('val/accuracy', val_acc)\n",
    "        live.next_step()\n",
    "        \n",
    "        print(f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%\")\n",
    "        print(f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%\")\n",
    "        \n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            torch.save({\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'label_to_idx': label_to_idx,\n",
    "                'idx_to_label': idx_to_label,\n",
    "                'params': params\n",
    "            }, '../models/best_model.pth')\n",
    "            print(f\"Best model saved: {val_acc:.2f}%\")\n",
    "        \n",
    "        scheduler.step()\n",
    "    \n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    import seaborn as sns\n",
    "    \n",
    "    cm = confusion_matrix(val_labels, val_preds)\n",
    "    fig, ax = plt.subplots(figsize=(10, 8))\n",
    "    sns.heatmap(\n",
    "        cm,\n",
    "        annot=True,\n",
    "        fmt='d',\n",
    "        cmap='Blues',\n",
    "        xticklabels=[idx_to_label[i] for i in range(len(idx_to_label))],\n",
    "        yticklabels=[idx_to_label[i] for i in range(len(idx_to_label))],\n",
    "        ax=ax\n",
    "    )\n",
    "    ax.set_ylabel('True Label')\n",
    "    ax.set_xlabel('Predicted Label')\n",
    "    ax.set_title('Confusion Matrix')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.yticks(rotation=0)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    confusion_matrix_path = '../dvclive/plots/confusion_matrix.png'\n",
    "    Path(confusion_matrix_path).parent.mkdir(parents=True, exist_ok=True)\n",
    "    plt.savefig(confusion_matrix_path, dpi=150, bbox_inches='tight')\n",
    "    live.log_image('confusion_matrix.png', confusion_matrix_path)\n",
    "    plt.close()\n",
    "    \n",
    "    live.log_metric('best_val_accuracy', best_val_acc)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
