{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "2da3530f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: mps\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "from dvclive import Live\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import models, transforms\n",
    "from PIL import Image, ImageFile\n",
    "from tqdm import tqdm\n",
    "import yaml\n",
    "\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "\n",
    "device = torch.device(\"mps\") if torch.backends.mps.is_available() else torch.device(\"cpu\")\n",
    "print(f\"Device: {device}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "19f3b3eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters:\n",
      "augmentation:\n",
      "  brightness: 0.2\n",
      "  contrast: 0.2\n",
      "  crop_size: 224\n",
      "  resize: 384\n",
      "data:\n",
      "  random_state: 42\n",
      "  train_test_split: 0.2\n",
      "model:\n",
      "  name: efficientnet_v2_m\n",
      "  num_classes: 5\n",
      "  pretrained: IMAGENET1K_V1\n",
      "scheduler:\n",
      "  gamma: 0.1\n",
      "  step_size: 5\n",
      "training:\n",
      "  batch_size: 32\n",
      "  learning_rate: 0.001\n",
      "  num_epochs: 20\n",
      "  optimizer: Adam\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open('../params.yaml', 'r') as f:\n",
    "    params = yaml.safe_load(f)\n",
    "\n",
    "print(\"Parameters:\")\n",
    "print(yaml.dump(params, default_flow_style=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "d6974ff1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (12000, 6)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('../data/balanced_animals_dataset.csv')\n",
    "print(f\"Dataset shape: {df.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "12ba29a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_to_idx = {label: idx for idx, label in enumerate(df['scientific_name'].unique())}\n",
    "idx_to_label = {idx: label for label, idx in label_to_idx.items()}\n",
    "df['label'] = df['scientific_name'].map(label_to_idx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "46a84d20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 9600, Val: 2400\n"
     ]
    }
   ],
   "source": [
    "train_df, val_df = train_test_split(\n",
    "    df, \n",
    "    test_size=params['data']['train_test_split'], \n",
    "    stratify=df['label'], \n",
    "    random_state=params['data']['random_state']\n",
    ")\n",
    "\n",
    "print(f\"Train: {len(train_df)}, Val: {len(val_df)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "9e973b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AnimalDataset(Dataset):\n",
    "    def __init__(self, dataframe, transform=None):\n",
    "        self.df = dataframe.reset_index(drop=True)\n",
    "        self.transform = transform\n",
    "        self.base_path = Path('../animal_images')\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        species = row['scientific_name'].replace(' ', '_')\n",
    "        img_path = self.base_path / species / f\"{row['uuid']}.jpg\"\n",
    "        \n",
    "        try:\n",
    "            image = Image.open(img_path).convert('RGB')\n",
    "        except Exception:\n",
    "            image = Image.new('RGB', (224, 224), color=(0, 0, 0))\n",
    "            \n",
    "        label = row['label']\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            \n",
    "        return image, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "60b59aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize(params['augmentation']['resize']),\n",
    "    transforms.RandomCrop(params['augmentation']['crop_size']),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ColorJitter(\n",
    "        brightness=params['augmentation']['brightness'],\n",
    "        contrast=params['augmentation']['contrast'],\n",
    "        saturation=params['augmentation']['contrast']\n",
    "    ),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize(params['augmentation']['resize']),\n",
    "    transforms.CenterCrop(params['augmentation']['crop_size']),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "087f23d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = AnimalDataset(train_df, transform=train_transform)\n",
    "val_dataset = AnimalDataset(val_df, transform=val_transform)\n",
    "\n",
    "batch_size = params['training']['batch_size']\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "9d20f037",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: efficientnet_v2_m\n",
      "Trainable parameters: 6,405\n"
     ]
    }
   ],
   "source": [
    "if params['model']['name'] == 'resnet50':\n",
    "    weights = getattr(models.ResNet50_Weights, params['model']['pretrained'])\n",
    "    model = models.resnet50(weights=weights)\n",
    "    num_features = model.fc.in_features\n",
    "    model.fc = nn.Linear(num_features, params['model']['num_classes'])\n",
    "    \n",
    "elif params['model']['name'] == 'resnet101':\n",
    "    weights = getattr(models.ResNet101_Weights, params['model']['pretrained'])\n",
    "    model = models.resnet101(weights=weights)\n",
    "    num_features = model.fc.in_features\n",
    "    model.fc = nn.Linear(num_features, params['model']['num_classes'])\n",
    "    \n",
    "elif params['model']['name'] == 'efficientnet_v2_m':\n",
    "    weights = getattr(models.EfficientNet_V2_M_Weights, params['model']['pretrained'])\n",
    "    model = models.efficientnet_v2_m(weights=weights)\n",
    "    num_features = model.classifier[1].in_features\n",
    "    model.classifier[1] = nn.Linear(num_features, params['model']['num_classes'])\n",
    "    \n",
    "elif params['model']['name'] == 'convnext_base':\n",
    "    weights = getattr(models.ConvNeXt_Base_Weights, params['model']['pretrained'])\n",
    "    model = models.convnext_base(weights=weights)\n",
    "    num_features = model.classifier[2].in_features\n",
    "    model.classifier[2] = nn.Linear(num_features, params['model']['num_classes'])\n",
    "    \n",
    "elif params['model']['name'] == 'vit_b_16':\n",
    "    weights = getattr(models.ViT_B_16_Weights, params['model']['pretrained'])\n",
    "    model = models.vit_b_16(weights=weights)\n",
    "    num_features = model.heads.head.in_features\n",
    "    model.heads.head = nn.Linear(num_features, params['model']['num_classes'])\n",
    "\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Разморозить последний слой\n",
    "if 'efficientnet' in params['model']['name']:\n",
    "    for param in model.classifier.parameters():\n",
    "        param.requires_grad = True\n",
    "elif 'convnext' in params['model']['name']:\n",
    "    for param in model.classifier.parameters():\n",
    "        param.requires_grad = True\n",
    "elif 'vit' in params['model']['name']:\n",
    "    for param in model.heads.parameters():\n",
    "        param.requires_grad = True\n",
    "else:\n",
    "    for param in model.fc.parameters():\n",
    "        param.requires_grad = True\n",
    "\n",
    "model = model.to(device)\n",
    "print(f\"Model: {params['model']['name']}\")\n",
    "print(f\"Trainable parameters: {sum(p.numel() for p in model.parameters() if p.requires_grad):,}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "e63049f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Получить параметры для обучения в зависимости от модели\n",
    "if 'efficientnet' in params['model']['name']:\n",
    "    trainable_params = model.classifier.parameters()\n",
    "elif 'convnext' in params['model']['name']:\n",
    "    trainable_params = model.classifier.parameters()\n",
    "elif 'vit' in params['model']['name']:\n",
    "    trainable_params = model.heads.parameters()\n",
    "else:\n",
    "    trainable_params = model.fc.parameters()\n",
    "\n",
    "optimizer = optim.Adam(trainable_params, lr=params['training']['learning_rate'])\n",
    "scheduler = optim.lr_scheduler.StepLR(\n",
    "    optimizer, \n",
    "    step_size=params['scheduler']['step_size'], \n",
    "    gamma=params['scheduler']['gamma']\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "61083b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, loader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for images, labels in tqdm(loader, desc=\"Training\"):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "    \n",
    "    return running_loss / len(loader), 100. * correct / total\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "dcd78141",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, loader, criterion, device):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(loader, desc=\"Validation\"):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "            \n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    return running_loss / len(loader), 100. * correct / total, np.array(all_preds), np.array(all_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "2804810a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 300/300 [01:58<00:00,  2.54it/s]\n",
      "Validation: 100%|██████████| 75/75 [00:23<00:00,  3.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.2884, Train Acc: 47.26%\n",
      "Val Loss: 1.0756, Val Acc: 58.83%\n",
      "Best model saved: 58.83%\n",
      "\n",
      "Epoch 2/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 300/300 [01:55<00:00,  2.60it/s]\n",
      "Validation: 100%|██████████| 75/75 [00:23<00:00,  3.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.1979, Train Acc: 51.75%\n",
      "Val Loss: 1.0135, Val Acc: 61.25%\n",
      "Best model saved: 61.25%\n",
      "\n",
      "Epoch 3/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 300/300 [01:54<00:00,  2.61it/s]\n",
      "Validation: 100%|██████████| 75/75 [00:23<00:00,  3.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.1760, Train Acc: 53.03%\n",
      "Val Loss: 1.0088, Val Acc: 60.92%\n",
      "\n",
      "Epoch 4/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 300/300 [01:54<00:00,  2.61it/s]\n",
      "Validation: 100%|██████████| 75/75 [00:23<00:00,  3.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.1626, Train Acc: 53.43%\n",
      "Val Loss: 1.0018, Val Acc: 60.46%\n",
      "\n",
      "Epoch 5/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 300/300 [01:54<00:00,  2.62it/s]\n",
      "Validation: 100%|██████████| 75/75 [00:23<00:00,  3.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.1641, Train Acc: 53.02%\n",
      "Val Loss: 0.9933, Val Acc: 61.38%\n",
      "Best model saved: 61.38%\n",
      "\n",
      "Epoch 6/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 300/300 [01:56<00:00,  2.57it/s]\n",
      "Validation: 100%|██████████| 75/75 [00:23<00:00,  3.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.1371, Train Acc: 54.93%\n",
      "Val Loss: 0.9883, Val Acc: 62.54%\n",
      "Best model saved: 62.54%\n",
      "\n",
      "Epoch 7/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 300/300 [01:53<00:00,  2.64it/s]\n",
      "Validation: 100%|██████████| 75/75 [00:23<00:00,  3.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.1468, Train Acc: 54.11%\n",
      "Val Loss: 0.9807, Val Acc: 62.71%\n",
      "Best model saved: 62.71%\n",
      "\n",
      "Epoch 8/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 300/300 [01:56<00:00,  2.57it/s]\n",
      "Validation: 100%|██████████| 75/75 [00:24<00:00,  3.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.1450, Train Acc: 54.38%\n",
      "Val Loss: 0.9792, Val Acc: 62.58%\n",
      "\n",
      "Epoch 9/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 300/300 [01:56<00:00,  2.57it/s]\n",
      "Validation: 100%|██████████| 75/75 [00:23<00:00,  3.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.1531, Train Acc: 54.01%\n",
      "Val Loss: 0.9715, Val Acc: 63.33%\n",
      "Best model saved: 63.33%\n",
      "\n",
      "Epoch 10/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 300/300 [01:56<00:00,  2.57it/s]\n",
      "Validation: 100%|██████████| 75/75 [00:23<00:00,  3.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.1440, Train Acc: 54.62%\n",
      "Val Loss: 0.9775, Val Acc: 62.75%\n",
      "\n",
      "Epoch 11/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 300/300 [01:56<00:00,  2.57it/s]\n",
      "Validation: 100%|██████████| 75/75 [00:23<00:00,  3.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.1448, Train Acc: 54.41%\n",
      "Val Loss: 0.9806, Val Acc: 62.46%\n",
      "\n",
      "Epoch 12/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 300/300 [01:55<00:00,  2.60it/s]\n",
      "Validation: 100%|██████████| 75/75 [00:24<00:00,  3.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.1357, Train Acc: 54.74%\n",
      "Val Loss: 0.9806, Val Acc: 62.96%\n",
      "\n",
      "Epoch 13/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 300/300 [01:57<00:00,  2.56it/s]\n",
      "Validation: 100%|██████████| 75/75 [00:23<00:00,  3.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.1418, Train Acc: 54.65%\n",
      "Val Loss: 0.9828, Val Acc: 62.58%\n",
      "\n",
      "Epoch 14/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 300/300 [01:56<00:00,  2.57it/s]\n",
      "Validation: 100%|██████████| 75/75 [00:24<00:00,  3.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.1331, Train Acc: 54.79%\n",
      "Val Loss: 0.9950, Val Acc: 62.54%\n",
      "\n",
      "Epoch 15/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 300/300 [01:57<00:00,  2.56it/s]\n",
      "Validation: 100%|██████████| 75/75 [00:23<00:00,  3.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.1410, Train Acc: 54.35%\n",
      "Val Loss: 0.9882, Val Acc: 62.38%\n",
      "\n",
      "Epoch 16/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 300/300 [02:07<00:00,  2.35it/s]\n",
      "Validation: 100%|██████████| 75/75 [00:23<00:00,  3.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.1383, Train Acc: 54.68%\n",
      "Val Loss: 0.9852, Val Acc: 62.46%\n",
      "\n",
      "Epoch 17/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 300/300 [01:54<00:00,  2.61it/s]\n",
      "Validation: 100%|██████████| 75/75 [00:23<00:00,  3.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.1399, Train Acc: 54.94%\n",
      "Val Loss: 0.9769, Val Acc: 63.04%\n",
      "\n",
      "Epoch 18/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 300/300 [01:54<00:00,  2.62it/s]\n",
      "Validation: 100%|██████████| 75/75 [00:23<00:00,  3.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.1423, Train Acc: 54.36%\n",
      "Val Loss: 0.9809, Val Acc: 62.12%\n",
      "\n",
      "Epoch 19/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 300/300 [01:56<00:00,  2.57it/s]\n",
      "Validation: 100%|██████████| 75/75 [00:24<00:00,  3.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.1420, Train Acc: 54.24%\n",
      "Val Loss: 0.9729, Val Acc: 63.00%\n",
      "\n",
      "Epoch 20/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 300/300 [02:10<00:00,  2.29it/s]\n",
      "Validation: 100%|██████████| 75/75 [00:27<00:00,  2.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.1363, Train Acc: 54.67%\n",
      "Val Loss: 0.9918, Val Acc: 62.50%\n"
     ]
    }
   ],
   "source": [
    "num_epochs = params['training']['num_epochs']\n",
    "best_val_acc = 0.0\n",
    "Path('../models').mkdir(exist_ok=True)\n",
    "\n",
    "with Live(dir='../dvclive', save_dvc_exp=True) as live:\n",
    "    \n",
    "    live.log_params(params)\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n",
    "        \n",
    "        train_loss, train_acc = train_epoch(\n",
    "            model, train_loader, criterion, optimizer, device\n",
    "        )\n",
    "        val_loss, val_acc, val_preds, val_labels = validate(\n",
    "            model, val_loader, criterion, device\n",
    "        )\n",
    "        \n",
    "        live.log_metric('train/loss', train_loss)\n",
    "        live.log_metric('train/accuracy', train_acc)\n",
    "        live.log_metric('val/loss', val_loss)\n",
    "        live.log_metric('val/accuracy', val_acc)\n",
    "        live.next_step()\n",
    "        \n",
    "        print(f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%\")\n",
    "        print(f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%\")\n",
    "        \n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            torch.save({\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'label_to_idx': label_to_idx,\n",
    "                'idx_to_label': idx_to_label,\n",
    "                'params': params\n",
    "            }, '../models/best_model.pth')\n",
    "            print(f\"Best model saved: {val_acc:.2f}%\")\n",
    "        \n",
    "        scheduler.step()\n",
    "    \n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    import seaborn as sns\n",
    "    \n",
    "    cm = confusion_matrix(val_labels, val_preds)\n",
    "    fig, ax = plt.subplots(figsize=(10, 8))\n",
    "    sns.heatmap(\n",
    "        cm,\n",
    "        annot=True,\n",
    "        fmt='d',\n",
    "        cmap='Blues',\n",
    "        xticklabels=[idx_to_label[i] for i in range(len(idx_to_label))],\n",
    "        yticklabels=[idx_to_label[i] for i in range(len(idx_to_label))],\n",
    "        ax=ax\n",
    "    )\n",
    "    ax.set_ylabel('True Label')\n",
    "    ax.set_xlabel('Predicted Label')\n",
    "    ax.set_title('Confusion Matrix')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.yticks(rotation=0)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    confusion_matrix_path = '../dvclive/plots/confusion_matrix.png'\n",
    "    Path(confusion_matrix_path).parent.mkdir(parents=True, exist_ok=True)\n",
    "    plt.savefig(confusion_matrix_path, dpi=150, bbox_inches='tight')\n",
    "    live.log_image('confusion_matrix.png', confusion_matrix_path)\n",
    "    plt.close()\n",
    "    \n",
    "    live.log_metric('best_val_accuracy', best_val_acc)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
