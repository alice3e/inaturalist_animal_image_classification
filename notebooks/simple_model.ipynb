{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2da3530f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alice3e/.pyenv/versions/3.11.13/lib/python3.11/site-packages/dvclive/monitor_system.py:11: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.\n",
      "  from pynvml import (\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: mps\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "from dvclive import Live\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import models, transforms\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "\n",
    "device = torch.device(\"mps\") if torch.backends.mps.is_available() else torch.device(\"cpu\")\n",
    "print(f\"Device: {device}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d6974ff1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (12000, 6)\n",
      "scientific_name\n",
      "Canis aureus              2400\n",
      "Canis familiaris          2400\n",
      "Canis familiaris dingo    2400\n",
      "Canis latrans             2400\n",
      "Canis lupus               2400\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('../data/balanced_animals_dataset.csv')\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(df['scientific_name'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "12ba29a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes: 5\n",
      "{'Canis aureus': 0, 'Canis familiaris': 1, 'Canis familiaris dingo': 2, 'Canis latrans': 3, 'Canis lupus': 4}\n"
     ]
    }
   ],
   "source": [
    "label_to_idx = {label: idx for idx, label in enumerate(df['scientific_name'].unique())}\n",
    "idx_to_label = {idx: label for label, idx in label_to_idx.items()}\n",
    "df['label'] = df['scientific_name'].map(label_to_idx)\n",
    "\n",
    "print(f\"Classes: {len(label_to_idx)}\")\n",
    "print(label_to_idx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "46a84d20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 9600, Val: 2400\n",
      "scientific_name\n",
      "Canis familiaris          1920\n",
      "Canis familiaris dingo    1920\n",
      "Canis aureus              1920\n",
      "Canis latrans             1920\n",
      "Canis lupus               1920\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "train_df, val_df = train_test_split(\n",
    "    df, \n",
    "    test_size=0.2, \n",
    "    stratify=df['label'], \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Train: {len(train_df)}, Val: {len(val_df)}\")\n",
    "print(train_df['scientific_name'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9e973b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AnimalDataset(Dataset):\n",
    "    def __init__(self, dataframe, transform=None):\n",
    "        self.df = dataframe.reset_index(drop=True)\n",
    "        self.transform = transform\n",
    "        self.base_path = Path('../animal_images')\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        species = row['scientific_name'].replace(' ', '_')\n",
    "        img_path = self.base_path / species / f\"{row['uuid']}.jpg\"\n",
    "        \n",
    "        try:\n",
    "            image = Image.open(img_path).convert('RGB')\n",
    "        except Exception as e:\n",
    "            image = Image.new('RGB', (224, 224), color=(0, 0, 0))\n",
    "            \n",
    "        label = row['label']\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            \n",
    "        return image, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "60b59aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.RandomCrop(224),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "087f23d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train batches: 300\n",
      "Val batches: 75\n"
     ]
    }
   ],
   "source": [
    "train_dataset = AnimalDataset(train_df, transform=train_transform)\n",
    "val_dataset = AnimalDataset(val_df, transform=val_transform)\n",
    "\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "\n",
    "print(f\"Train batches: {len(train_loader)}\")\n",
    "print(f\"Val batches: {len(val_loader)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9d20f037",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V1)\n",
    "\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "num_features = model.fc.in_features\n",
    "model.fc = nn.Linear(num_features, len(label_to_idx))\n",
    "\n",
    "model = model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e63049f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.fc.parameters(), lr=0.001)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "61083b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch_with_live(model, loader, criterion, optimizer, device, live):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for images, labels in tqdm(loader, desc=\"Training\"):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "    \n",
    "    epoch_loss = running_loss / len(loader)\n",
    "    epoch_acc = 100. * correct / total\n",
    "    return epoch_loss, epoch_acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dcd78141",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_with_live(model, loader, criterion, device, live):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(loader, desc=\"Validation\"):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "            \n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    epoch_loss = running_loss / len(loader)\n",
    "    epoch_acc = 100. * correct / total\n",
    "    return epoch_loss, epoch_acc, np.array(all_preds), np.array(all_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2804810a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 300/300 [01:14<00:00,  4.00it/s]\n",
      "Validation: 100%|██████████| 75/75 [00:15<00:00,  4.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.1499, Train Acc: 55.01%\n",
      "Val Loss: 0.9373, Val Acc: 64.92%\n",
      "Best model saved with val_acc: 64.92%\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 1\n",
    "best_val_acc = 0.0\n",
    "Path('../models').mkdir(exist_ok=True)\n",
    "\n",
    "with Live(dir='../dvclive', save_dvc_exp=True) as live:\n",
    "    \n",
    "    live.log_params({\n",
    "        'model': 'resnet50',\n",
    "        'pretrained': 'IMAGENET1K_V1',\n",
    "        'batch_size': batch_size,\n",
    "        'learning_rate': 0.001,\n",
    "        'num_epochs': num_epochs,\n",
    "        'optimizer': 'Adam',\n",
    "        'scheduler_step': 3,\n",
    "        'scheduler_gamma': 0.1,\n",
    "        'train_test_split': 0.2,\n",
    "        'image_size': 224,\n",
    "        'num_classes': len(label_to_idx)\n",
    "    })\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n",
    "        \n",
    "        train_loss, train_acc = train_epoch_with_live(\n",
    "            model, train_loader, criterion, optimizer, device, live\n",
    "        )\n",
    "        val_loss, val_acc, val_preds, val_labels = validate_with_live(\n",
    "            model, val_loader, criterion, device, live\n",
    "        )\n",
    "        \n",
    "        live.log_metric('train/loss', train_loss)\n",
    "        live.log_metric('train/accuracy', train_acc)\n",
    "        live.log_metric('val/loss', val_loss)\n",
    "        live.log_metric('val/accuracy', val_acc)\n",
    "        live.next_step()\n",
    "        \n",
    "        print(f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%\")\n",
    "        print(f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%\")\n",
    "        \n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            torch.save(model.state_dict(), '../models/best_model.pth')\n",
    "            print(f\"Best model saved with val_acc: {val_acc:.2f}%\")\n",
    "        \n",
    "        scheduler.step()\n",
    "    \n",
    "    live.log_sklearn_plot(\n",
    "        'confusion_matrix',\n",
    "        val_labels,\n",
    "        val_preds,\n",
    "        name='confusion_matrix',\n",
    "        labels=[idx_to_label[i] for i in range(len(idx_to_label))]\n",
    "    )\n",
    "    \n",
    "    live.log_metric('best_val_accuracy', best_val_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7c291dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(\n",
    "    val_labels, \n",
    "    val_preds, \n",
    "    target_names=[idx_to_label[i] for i in range(len(idx_to_label))]\n",
    "))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af236618",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final checkpoint saved. Best validation accuracy: 67.46%\n"
     ]
    }
   ],
   "source": [
    "# torch.save({\n",
    "#     'model_state_dict': model.state_dict(),\n",
    "#     'optimizer_state_dict': optimizer.state_dict(),\n",
    "#     'label_to_idx': label_to_idx,\n",
    "#     'idx_to_label': idx_to_label,\n",
    "#     'best_val_acc': best_val_acc\n",
    "# }, '../models/final_checkpoint.pth')\n",
    "\n",
    "# print(f\"Final checkpoint saved. Best validation accuracy: {best_val_acc:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e8efc3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path('../models').mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c1fa81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics saved\n"
     ]
    }
   ],
   "source": [
    "# import json\n",
    "\n",
    "# metrics = {\n",
    "#     'best_val_accuracy': best_val_acc,\n",
    "#     'final_train_accuracy': history['train_acc'][-1],\n",
    "#     'final_val_accuracy': history['val_acc'][-1],\n",
    "#     'final_train_loss': history['train_loss'][-1],\n",
    "#     'final_val_loss': history['val_loss'][-1],\n",
    "#     'num_epochs': num_epochs,\n",
    "#     'num_classes': len(label_to_idx)\n",
    "# }\n",
    "\n",
    "# with open('../metrics.json', 'w') as f:\n",
    "#     json.dump(metrics, f, indent=4)\n",
    "\n",
    "# print(\"Metrics saved\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
